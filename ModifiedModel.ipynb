{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Table of Contents\n",
    "[A Naive Classifier](#anc)  \n",
    "[Char Logistic Model](#clm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<a name=\"anc\"></a>\n",
    "# Tesing the Naive Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "This is a simple logistic regression classifier used by WikiMedia in its demo  \n",
    "But I dont think it is the model they use in their public dataset  \n",
    "A more comprehensive model is elaborated below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import sys\n",
    "import os\n",
    "path = './TalkData/computed_dataset/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "comments_dir = os.path.join(path, 'attack_annotated_comments.tsv')\n",
    "annotations_dir = os.path.join(path, 'attack_annotations.tsv')\n",
    "comments = pd.read_csv(comments_dir, sep='\\t', index_col=0)\n",
    "annotations = pd.read_csv(annotations_dir, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rev_id\n",
       "801279             Iraq is not good  ===  ===  USA is bad   \n",
       "2702703      ____ fuck off you little asshole. If you wan...\n",
       "4632658         i have a dick, its bigger than yours! hahaha\n",
       "6545332      == renault ==  you sad little bpy for drivin...\n",
       "6545351      == renault ==  you sad little bo for driving...\n",
       "Name: comment, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = annotations.groupby('rev_id')['attack'].mean()>.5\n",
    "comments['attack'] = labels\n",
    "comments['comment'] = comments['comment'].apply(lambda x: x.replace(\"NEWLINE_TOKEN\", \" \"))\n",
    "comments['comment'] = comments['comment'].apply(lambda x: x.replace(\"TAB_TOKEN\", \" \"))\n",
    "comments.query('attack')['comment'].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.956968629551\n"
     ]
    }
   ],
   "source": [
    "training = comments.query('split == \"train\"')\n",
    "testing = comments.query('split == \"test\"')\n",
    "\n",
    "clf = Pipeline([\n",
    "    ('vect', CountVectorizer(max_features=10000, ngram_range=(1,2))),\n",
    "    ('tfidf', TfidfTransformer(norm='l2')),\n",
    "    ('clf', LogisticRegression())\n",
    "])\n",
    "clf = clf.fit(training['comment'], training['attack'])\n",
    "auc = roc_auc_score(testing['attack'], clf.predict_proba(testing['comment'])[:,1])\n",
    "print(auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<a name='clm'></a>\n",
    "# Char-Logistic Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "After searching for some time, I think this is the right model they described in their paper.   \n",
    "Unfortunately, they did not publicize their api, so I grabed some of their code and made a slightly modifed version for our own use.\n",
    "\n",
    "**Requirements**\n",
    "* BeautifulSoup4\n",
    "* Joblib\n",
    "* mwparserfromhell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Step 0\n",
    "get to the github directory where all wikiMedia files / data exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "WMdir = '/home/ubuntu/wikipedia/TalkAnalytics/ClonedModel/wmModel/wiki-detox/' # need to change this directory\n",
    "sys.path.append(WMdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Step 1\n",
    "Clean the dataset using the **diff_utils** functions provided by WikiMedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import requests\n",
    "import sys\n",
    "import os\n",
    "import inspect\n",
    "from pprint import pprint\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import src.data_generation.diff_utils as diff_utils\n",
    "\n",
    "def diff_and_clean(data):\n",
    "    ''' taking the diff and clean the text column'''\n",
    "    \n",
    "    titles = data.title.unique()\n",
    "    for title in titles:\n",
    "        data_subset = data[data.title == title]\n",
    "\n",
    "        text_new = data_subset.text[1:]\n",
    "        text_old = data_subset.text[:-1]\n",
    "        text_diff = [data_subset.text.iloc[0]]\n",
    "\n",
    "        for [new,old] in zip(text_new,text_old):\n",
    "            if(type(new) is not str):\n",
    "                print(\"text is not str: %s, changed to empty\"%(new))\n",
    "                new = ''\n",
    "            if(type(old) is not str):\n",
    "                print(\"text is not str: %s, changed to empty\"%(old))\n",
    "                old = ''\n",
    "                \n",
    "            text_diff.append(new.replace(old,''))\n",
    "        # the diff_utils function requires a column named \"insertion\n",
    "        data.loc[data.title==title,'insertion'] = text_diff\n",
    "    data = diff_utils.clean_and_filter(data)\n",
    "    return data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Step 2\n",
    "Build Models    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Step 2.1** Load pre_trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/base.py:315: UserWarning: Trying to unpickle estimator CountVectorizer from version 0.18 when using version 0.18.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/base.py:315: UserWarning: Trying to unpickle estimator TfidfTransformer from version 0.18 when using version 0.18.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/base.py:315: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.18 when using version 0.18.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/base.py:315: UserWarning: Trying to unpickle estimator Pipeline from version 0.18 when using version 0.18.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import joblib\n",
    "\n",
    "def load_pipeline(directory):\n",
    "    if os.path.isfile(directory):\n",
    "        return joblib.load(directory)\n",
    "    else:\n",
    "        print(\"pipeline not found\")\n",
    "        return None\n",
    "    \n",
    "# load the sklearn .pkl pipline from WikiMedia\n",
    "\n",
    "aggresion_model_dir = os.path.join(WMdir,'app/models/aggression_linear_char_oh_pipeline.pkl')\n",
    "attack_model_dir = os.path.join(WMdir,'app/models/attack_linear_char_oh_pipeline.pkl')\n",
    "\n",
    "model_dict = {\n",
    "    'aggresion': load_pipeline(aggresion_model_dir),\n",
    "    'attack': load_pipeline(attack_model_dir)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Step 2.2** Define functions to apply models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def apply_models_DF(df, col):\n",
    "    ''' Predict the probability of input data to be labelled\n",
    "        'aggressive' or 'attack'\n",
    "        \n",
    "        Input:\n",
    "        ======\n",
    "        df:   dataFrame to be predicted\n",
    "        col:  name of the column that stores the texts\n",
    "        \n",
    "    '''\n",
    "    \n",
    "    texts = df[col]\n",
    "    for task,model in model_dict.items():\n",
    "        scores = model.predict_proba(texts)[:,1]\n",
    "        df['pred_%s_score_uncalibrated'%(task)] = scores\n",
    "    return df\n",
    "\n",
    "def apply_models_text(text):\n",
    "    ''' Predict the probability of input texts to be labelled\n",
    "        'aggressive' or 'attack'\n",
    "        \n",
    "        Input:\n",
    "        ======\n",
    "        text:  comments to be predicted\n",
    "        \n",
    "    '''\n",
    "\n",
    "    for task,model in model_dict.items():\n",
    "        scores = model.predict_proba([text])[:,1]\n",
    "        print('pred_%s_score_uncalibrated: %f'%(task,scores))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "comments_dir = './TalkData/computed_dataset/aggression_annotated_comments.tsv'\n",
    "data = pd.read_csv(comments_dir, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "comments = data.comment\n",
    "data['comment'] = data['comment'].apply(lambda x: x.replace(\"NEWLINE_TOKEN\", \" \"))\n",
    "data['comment'] = data['comment'].apply(lambda x: x.replace(\"TAB_TOKEN\", \" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred_aggresion_score_uncalibrated: 0.003575\n",
      "pred_attack_score_uncalibrated: 0.002437\n"
     ]
    }
   ],
   "source": [
    "text = data.comment[0]\n",
    "apply_models_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred_aggresion_score_uncalibrated: 0.958296\n",
      "pred_attack_score_uncalibrated: 0.747354\n",
      "pred_aggresion_score_uncalibrated: 0.017243\n",
      "pred_attack_score_uncalibrated: 0.013077\n"
     ]
    }
   ],
   "source": [
    "apply_models_text('damn')\n",
    "apply_models_text('well done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text is not str: nan, changed to empty\n",
      "text is not str: nan, changed to empty\n",
      "text is not str: nan, changed to empty\n",
      "text is not str: nan, changed to empty\n"
     ]
    }
   ],
   "source": [
    "test_data = pd.read_csv('parsed.csv', sep='\\t', nrows=1000)\n",
    "test_data = diff_and_clean(test_data)\n",
    "\n",
    "# remove redundant columns\n",
    "test_data['clean_text'] = test_data['clean_diff']\n",
    "test_data = test_data.drop(['text','diff','clean_diff'],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "test_data = apply_models_DF(test_data, 'clean_text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Biggest CROOK \n",
      "\n",
      "Lalit Modi is the one of the biggest crook in Indian History. This guy should hanged with rest. He is all about making money, even cutting others throat. His biggest supporters are BJP, which is also uneducated losers want to make Indian free from foreign investment. These bums never realized India is the way it today because foreign investment. Anyway, get rid off  Lalit Modi from his IPL post, send him to Jail.\n",
      "0.236954043285 0.171614240261\n"
     ]
    }
   ],
   "source": [
    "demo_idx = 798\n",
    "print(test_data.clean_text[demo_idx])\n",
    "print(test_data.pred_aggresion_score_uncalibrated[demo_idx],test_data.pred_attack_score_uncalibrated[demo_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>byte</th>\n",
       "      <th>comment</th>\n",
       "      <th>time</th>\n",
       "      <th>title</th>\n",
       "      <th>user</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>pred_aggresion_score_uncalibrated</th>\n",
       "      <th>pred_attack_score_uncalibrated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>307</td>\n",
       "      <td>Project tag</td>\n",
       "      <td>2009-01-20T02:04:31Z</td>\n",
       "      <td>Jagatballavpur (community development block)</td>\n",
       "      <td>Chandan Guha</td>\n",
       "      <td>Map\\nThe map has been created with coordinates...</td>\n",
       "      <td>0.005145</td>\n",
       "      <td>0.001985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>cities -&gt; geography</td>\n",
       "      <td>2011-10-20T09:28:30Z</td>\n",
       "      <td>Jagatballavpur (community development block)</td>\n",
       "      <td>Chandan Guha</td>\n",
       "      <td>Map\\nThe map has been created with coordinates...</td>\n",
       "      <td>0.005145</td>\n",
       "      <td>0.001985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>141</td>\n",
       "      <td>/* Map */</td>\n",
       "      <td>2011-10-20T09:30:10Z</td>\n",
       "      <td>Jagatballavpur (community development block)</td>\n",
       "      <td>Chandan Guha</td>\n",
       "      <td>It now has Jagatballavpur coordinates. -</td>\n",
       "      <td>0.004637</td>\n",
       "      <td>0.005583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1131</td>\n",
       "      <td>Notification of altered sources needing review...</td>\n",
       "      <td>2016-11-14T21:22:02Z</td>\n",
       "      <td>Captain Strong</td>\n",
       "      <td>InternetArchiveBot</td>\n",
       "      <td>External links modified \\n\\nHello fellow Wiki...</td>\n",
       "      <td>0.003740</td>\n",
       "      <td>0.002265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>447</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013-02-01T07:38:18Z</td>\n",
       "      <td>Foreigners (Protected Areas) Order 1958 (India)</td>\n",
       "      <td>2001:208:5:801:F412:ADB7:2F0E:5507</td>\n",
       "      <td>Something to note is that the PAP has been sus...</td>\n",
       "      <td>0.006208</td>\n",
       "      <td>0.011630</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    byte                                            comment  \\\n",
       "0    307                                        Project tag   \n",
       "2     20                                cities -> geography   \n",
       "3    141                                          /* Map */   \n",
       "15  1131  Notification of altered sources needing review...   \n",
       "32   447                                                NaN   \n",
       "\n",
       "                    time                                            title  \\\n",
       "0   2009-01-20T02:04:31Z     Jagatballavpur (community development block)   \n",
       "2   2011-10-20T09:28:30Z     Jagatballavpur (community development block)   \n",
       "3   2011-10-20T09:30:10Z     Jagatballavpur (community development block)   \n",
       "15  2016-11-14T21:22:02Z                                   Captain Strong   \n",
       "32  2013-02-01T07:38:18Z  Foreigners (Protected Areas) Order 1958 (India)   \n",
       "\n",
       "                                  user  \\\n",
       "0                         Chandan Guha   \n",
       "2                         Chandan Guha   \n",
       "3                         Chandan Guha   \n",
       "15                  InternetArchiveBot   \n",
       "32  2001:208:5:801:F412:ADB7:2F0E:5507   \n",
       "\n",
       "                                           clean_text  \\\n",
       "0   Map\\nThe map has been created with coordinates...   \n",
       "2   Map\\nThe map has been created with coordinates...   \n",
       "3         It now has Jagatballavpur coordinates. -      \n",
       "15   External links modified \\n\\nHello fellow Wiki...   \n",
       "32  Something to note is that the PAP has been sus...   \n",
       "\n",
       "    pred_aggresion_score_uncalibrated  pred_attack_score_uncalibrated  \n",
       "0                            0.005145                        0.001985  \n",
       "2                            0.005145                        0.001985  \n",
       "3                            0.004637                        0.005583  \n",
       "15                           0.003740                        0.002265  \n",
       "32                           0.006208                        0.011630  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
